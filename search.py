import pandas as pd
import openpyxl
import requests
import argparse
import pytz
import json
import time
import csv
import sys
import os
from datetime import datetime, timedelta

global csvwrite
global k
opx = openpyxl

def getApiKey():  # retrieves API_KEY for NVD
    # api_txt = open('api_key.txt','r')
    # API_KEY = api_txt.read()
    # api_txt.close()
    API_KEY = os.getenv("NVD_API_KEY")
    return API_KEY


def kwSearch(keywords, mTrig=False):  # Searching NVD API for keywords
    print("Searching for New/Modified CVEs for " + str(keywords))
    time = datetime.now().strftime("%Y-%m-%dT%H:%M:%S.%fZ")
    delta = datetime.now() - timedelta(days=7)  # Only Modified since last week
    lastweek = delta.strftime("%Y-%m-%dT%H:%M:%S.%fZ")
    url = "https://services.nvd.nist.gov/rest/json/cves/2.0/"
    headers = {"apiKey": getApiKey()}
    params = {
        "keywordSearch": keywords,
        "lastModStartDate": lastweek,
        "lastModEndDate": time,
    }
    if mTrig:
        params.update({"resultsPerPage": "5"})  # If mTrig is True, trigger Mini Mode
    r = requests.get(url, headers=headers, params=params)
    try:
        cves = r.json()
        for cve in cves["vulnerabilities"]:
            c = cve["cve"]
            print(str(c["id"]))
            # print(
            # "CVE: " + str(c['id']) + "\n"
            # "Last Modified: " + str(c['lastModified']) + "\n"
            # "Description: " + str(c['descriptions'][0]['value'])
            # )
            if "cvssMetricV31" in c["metrics"]:
                # print("Impact Score V31: " + str(c['metrics']['cvssMetricV31'][0]['impactScore']) + "\n")
                csvwrite.writerow(
                    [
                        str(c["id"]),
                        str(c["metrics"]["cvssMetricV31"][0]["impactScore"]),
                        str(k),
                        str(c["descriptions"][0]["value"]),
                        str(c["lastModified"]),
                    ]
                )
            elif "cvssMetricV30" in c["metrics"]:
                # print("Impact Score V2: " + str(c['metrics']['cvssMetricV30'][0]['impactScore']) + "\n")
                csvwrite.writerow(
                    [
                        str(c["id"]),
                        str(c["metrics"]["cvssMetricV30"][0]["impactScore"]),
                        str(k),
                        str(c["descriptions"][0]["value"]),
                        str(c["lastModified"]),
                    ]
                )
            elif "cvssMetricV2" in c["metrics"]:
                # print("Impact Score V2: " + str(c['metrics']['cvssMetricV2'][0]['impactScore']) + "\n")
                csvwrite.writerow(
                    [
                        str(c["id"]),
                        str(c["metrics"]["cvssMetricV2"][0]["impactScore"]),
                        str(k),
                        str(c["descriptions"][0]["value"]),
                        str(c["lastModified"]),
                    ]
                )
            else:
                # continue
                csvwrite.writerow(
                    [
                        str(c["id"]),
                        str("N/A"),
                        str(k),
                        str(c["descriptions"][0]["value"]),
                        str(c["lastModified"]),
                    ]
                )
            # print(c)
        # print(cves)
    except:
        print("Error: ", keywords, " ", r.status_code)  # exception for bad API requests


def csvWriter(mTrig=False):  # CSV creator
    print("Writing CSV")
    csvfile = open("cve.csv", mode="w", newline="")
    global csvwrite
    csvwrite = csv.writer(
        csvfile,
        dialect="excel",
        delimiter=",",
        quotechar='"',
        quoting=csv.QUOTE_MINIMAL,
    )
    csvwrite.writerow(["CVE", "Impact Score (1-10, 10 being the worst)", "Keyword", "Description", "Last Modified"])
    # csvwrite.writerow(['1234','1.2','test description','11-1-11'])
    global k
    for k in kwArray:
        if mTrig:
            kwSearch(k, mTrig)
            time.sleep(6)
        else:
            kwSearch(k)
            time.sleep(6)
    csvfile.close()


def dupeCheck():
    print("Eliminating Duplicates")
    with open("cve.csv", "r") as in_f, open("cve_unduped.csv", "w", newline="") as out_f:
        seen = set()
        for line in in_f:
            if line in seen:
                continue
            seen.add(line)
            out_f.write(line)
    in_f.close()
    out_f.close()


def checkSearchDupes(searchTerms):
    print("Checking for Search Term Duplicates...")
    setTerms = set()
    for term in searchTerms:
        if term in setTerms:
            sys.exit("Found Duplicate Term: " + term)
        else:
            setTerms.add(term)
    print("No duplicate Search Terms found, moving on...")


def sendToTeams():
    print("Sending to Teams")
    # f = open('teams_hook.txt','r')
    # url = f.read()
    # f.close()
    url = os.getenv("TEAMS_HOOK")
    headers = {"Content-Type": "application/json"}
    payload = {
        "text": "New Report posted in Repo https://raw.githubusercontent.com/SecurityTapestry-Queen/nvd-cve-api-search/main/cves.xlsx"
        +"<br>"
        + "New HTML https://securitytapestry-queen.github.io/nvd-cve-api-search/cve_tables.html"
    }
    r = requests.post(url, headers=headers, data=json.dumps(payload))
    print(r.text.encode("utf8"))
    # sys.exit('Done!')


def makeHtml():
    print('Making HTML')
    in_f = pd.read_csv('cve_unduped.csv', encoding='utf-8')
    tables = in_f.to_html(index=False, table_id="cve-table", classes="sortable")
    docsDir = "docs/"
    file = open(docsDir+"cve_tables.html","w")
    file.write(
          "<!DOCTYPE html><html><head>"+"\n"
        + "<title>CVE Report</title>"+"\n"
        + "<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">"+"\n"
        + "<style>" + "\n"
        + ".dataframe { font-family: Arial, Helvetica, sans-serif;border-collapse: collapse;width: 100%; }" + "\n"
        + ".dataframe td, .dataframe th { border: 1px solid #ddd;padding: 8px; }" + "\n"
        + ".dataframe tr:nth-child(even){background-color: #f2f2f2;}" + "\n"
        + ".dataframe tr:hover {background-color: #ddd;}" + "\n"
        + ".dataframe th {padding-top: 12px;padding-bottom: 12px;text-align: left;background-color: #04AA6D;color: white;cursor: pointer;}" + "\n"
        + ".table-container { width: 100%;overflow: scroll; }" + "\n"
        + "</style>"
        + "<script src=\"assets/sorttable.js\">"+"</script>"+"\n"
        + "</head><body>" + "\n"
        + "<div class=\"table-container\">"+"\n"
        + tables+"\n"
        + "</div>"
        + "</body>"+"\n"
        + "</html>"
        )
    print('Saved to docs/cve_tables.html')

def csvExcel(csv, excel):
    df = pd.read_csv(csv)
    writer = pd.ExcelWriter(excel)
    df.to_excel(writer, index=False)
    writer.close()

def xlsxArchiver(excel):
    archivePath = "archive/"
    CST = pytz.timezone("America/Chicago")
    now = datetime.now(CST)
    date_time = now.strftime("%m-%d-%Y-%H-%M-%S")
    os.system("cp "+excel+" "+archivePath+"report-"+date_time+".xlsx")
    print("XLSX Archived to "+archivePath+"report-"+date_time+".xlsx")

def htmlArchiver(html):
    archivePath = "archive/"
    CST = pytz.timezone("America/Chicago")
    now = datetime.now(CST)
    date_time = now.strftime("%m-%d-%Y-%H-%M-%S")
    os.system("cp "+html+" "+archivePath+"report-"+date_time+".html")
    print("HTML Archived to "+archivePath+"report-"+date_time+".html")

kwArray = [
".NET Framework",
"ADX","AMD","AWS","Adobe","Airflow","Airwatch","Amazon","Apache","Apple","Arris","Aruba","Atlassian","Azure","Atom","ASP.NET","AI","AnyDesk","AnyConnect","Atomic Red Team","Active Directory",
"BusyBox","Biometric","Bitcoin","Barracuda","Botnet","BitLocker",
"CSRF","Carbon Black","Cisco","Citrix","Crowdstrike","Cryptocurrency","Crypto","ChatGPT","CRM",
"D-Link","Darktrace","Defender","Dell","Discourse","Django","Docker","Dolibarr","Debian","DDoS","DRAGOS","Dynamics 365",
"EMC","ESXi","Eclipse","Elasticsearch","Ethereum","Excel","Exchange","Encyption","Exploit","ExtraHop","ExpressVPN","Endpoint",
"Fortinet","Freshworks","FreshService","Firewall","Fortra",
"GIS","GitLab","Go","Google","Gradle","Grafana","Git","GPT","GoAnywhere","GitHub",
"HP","Hadoop","HashiCorp","Hyper-V",
"IBM","IOBit","Intel","IoT","InTune","Insight",
"Java","Jenkins","JetBrains","Juniper","JQuery","Jira","JavaScript","JDK","JRE",
"Kibana","Kubernetes","KeePass","Kaspersky",
"Lenovo","Linux","Llama","Litecoin","LogMeIn","LastPass",
"MSI","Management","Mattermost","Microsoft","MongoDB","MySQL","MacOS","MariaDB","Malware","MFA","Multi-factor Authentication","Midjourney","Machine Learning","ML","MDR","MFT","MDM","McAfee","Malwarebytes","Mozilla",
"NVIDIA","Netgear","Nextcloud","Nginx","Node.js","NoSQL","Nexpose","Nessus",
"OAuth","Office365","Okta","OpenSSL","Oracle","Outlook","Office","OpenAI","OneDrive","OneNote","Office 365",
"PHP","Palo Alto","Powerpoint","Proofpoint","Python","Phishing","PipeDrive",
"QEMU","QGIS",
"RDP","Rapid7","Red Canary","Red Hat","Redis","Ransomware","Rootkit","Remote Desktop",
"SAP","SNMP","SQL","SSL","STARTTLS","SUSE","SentinelOne","SharePoint","Slack","Snapdragon","Solarwinds","StarWind","Samba","Spyware","Stable Diffusion","Symantec","SIP",
"TLS","Tenda","TensorFlow","TeamViewer",
"Ubiquity","Ubuntu",
"VMware","VNC","VPN","Visual Studio","VirtualBox","VM","VS Code","VoIP","Vim",
"Win32k","Windows","Word","WordPress","Wyse","Win64",
"Xen","Xterm","XSS",
"Zoho","Zoom","Zyxel",
]

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="NVD CVE API Scraper")
    parser.add_argument(
        "-m",
        "--mini-csv",
        help="Only checks for a few CVEs per Search Term",
        action="store_true",
        dest="Mini",
        default=False,
    )
    parser.add_argument(
        "-M",
        "--maxi-csv",
        help="Full-Sized Search",
        action="store_true",
        dest="Maxi",
        default=False,
    )
    parser.add_argument(
        "-t",
        "--send-to-teams",
        help="Sends Link to Teams Channel",
        action="store_true",
        dest="SendToTeams",
        default=False,
    )
    parser.add_argument(
        "-html",
        "--html-tables",
        help="Converts Output CSV to HTML Tables",
        action="store_true",
        dest="MakeHtml",
        default=False,
    )
    parser.add_argument(
        "-e",
        "--excel",
        help="Converts final CSV to Excel file",
        action="store_true",
        dest="MakeExcel",
        default=False,
    )
    parser.add_argument(
        "-a",
        "--archiver",
        help="Archives XLSX and HTML",
        action="store_true",
        dest="Archiver",
        default=False
    )
    args = parser.parse_args()

    if sys.version_info < (3, 10):
        sys.exit("Please use Python 3.10+")
    print("Search Terms Used:")
    print(*kwArray, sep=", ")

    checkSearchDupes(kwArray)

    if args.Mini:
        print("Mini Mode On")
        csvWriter(True)
        dupeCheck()

    if args.Maxi:
        print("Maxi Mode On")
        csvWriter()
        dupeCheck()

    if args.SendToTeams:
        sendToTeams()

    if args.MakeHtml:
        makeHtml()

    if args.MakeExcel:
        csvExcel('cve_unduped.csv','cves.xlsx')

    if args.Archiver:
        xlsxArchiver("cves.xlsx")
        htmlArchiver("docs/cve_tables.html")

    print('Done!')