import pandas as pd
import openpyxl
import requests
import argparse
import pytz
import json
import time
import csv
import sys
import os
from datetime import datetime, timedelta

global csvwrite
global dayArchive
global k
opx = openpyxl
archivePath = "archive/"
CST = pytz.timezone("America/Chicago")
now = datetime.now(CST)
date_time = now.strftime("%m-%d-%Y-%H-%M-%S")
date_today = now.strftime("%m-%d-%Y")

encodingWin="cp1252"
encodingLin="utf-8"

def getApiKey():  # retrieves API_KEY for NVD
    # api_txt = open('api_key.txt','r')
    # API_KEY = api_txt.read()
    # api_txt.close()
    API_KEY = os.getenv("NVD_API_KEY")
    if str(API_KEY) == "":
        print("Warning: NVD API Key not found, you may experience rate-limiting. Use -test or add API_KEY")
    return API_KEY


def kwSearch(keywords, mTrig=False):  # Searching NVD API for keywords
    print("Searching for New/Modified CVEs for " + str(keywords))
    time = datetime.now().strftime("%Y-%m-%dT%H:%M:%S.%fZ")
    delta = datetime.now() - timedelta(days=7)  # Only Modified since last week
    lastweek = delta.strftime("%Y-%m-%dT%H:%M:%S.%fZ")
    url = "https://services.nvd.nist.gov/rest/json/cves/2.0/"
    headers = {"apiKey": getApiKey()}
    params = {
        "keywordSearch": keywords,
        "lastModStartDate": lastweek,
        "lastModEndDate": time,
    }
    if mTrig:
        params.update({"resultsPerPage": "5"})  # If mTrig is True, trigger Mini Mode
    r = requests.get(url, headers=headers, params=params)
    try:
        cves = r.json()
        for cve in cves["vulnerabilities"]:
            c = cve["cve"]
            print(str(c["id"]))
            # print(
            # "CVE: " + str(c['id']) + "\n"
            # "Last Modified: " + str(c['lastModified']) + "\n"
            # "Description: " + str(c['descriptions'][0]['value'])
            # )
            if "cvssMetricV31" in c["metrics"]:
                # print("Impact Score V31: " + str(c['metrics']['cvssMetricV31'][0]['impactScore']) + "\n")
                csvwrite.writerow(
                    [
                        str(c["id"]),
                        str(c["metrics"]["cvssMetricV31"][0]["impactScore"]),
                        str(k),
                        str(c["descriptions"][0]["value"]),
                        str(c["lastModified"]),
                        str("https://cve.circl.lu/cve/"+c["id"]),
                    ]
                )
            elif "cvssMetricV30" in c["metrics"]:
                # print("Impact Score V2: " + str(c['metrics']['cvssMetricV30'][0]['impactScore']) + "\n")
                csvwrite.writerow(
                    [
                        str(c["id"]),
                        str(c["metrics"]["cvssMetricV30"][0]["impactScore"]),
                        str(k),
                        str(c["descriptions"][0]["value"]),
                        str(c["lastModified"]),
                        str("https://cve.circl.lu/cve/"+c["id"]),
                    ]
                )
            elif "cvssMetricV2" in c["metrics"]:
                # print("Impact Score V2: " + str(c['metrics']['cvssMetricV2'][0]['impactScore']) + "\n")
                csvwrite.writerow(
                    [
                        str(c["id"]),
                        str(c["metrics"]["cvssMetricV2"][0]["impactScore"]),
                        str(k),
                        str(c["descriptions"][0]["value"]),
                        str(c["lastModified"]),
                        str("https://cve.circl.lu/cve/"+c["id"]),
                    ]
                )
            else:
                # continue
                csvwrite.writerow(
                    [
                        str(c["id"]),
                        str("NA"),
                        str(k),
                        str(c["descriptions"][0]["value"]),
                        str(c["lastModified"]),
                        str("https://cve.circl.lu/cve/"+c["id"]),
                    ]
                )
            # print(c)
        # print(cves)
    except:
        print("Error: ", keywords, " ", r.status_code)  # exception for bad API requests


def csvWriter(mTrig=False,testTrigger=False):  # CSV creator
    print("Writing CSV")
    csvfile = open("cve.csv", mode="w", newline="")
    global csvwrite
    csvwrite = csv.writer(
        csvfile,
        dialect="excel",
        delimiter=",",
        quotechar='"',
        quoting=csv.QUOTE_MINIMAL,
    )
    csvwrite.writerow(["CVE", "Impact Score (1-10, 10 being the worst)", "Keyword", "Description", "Last Modified", "Link"])
    # csvwrite.writerow(['1234','1.2','test description','11-1-11'])
    global k
    if not testTrigger:
        for k in kwArray:
            if mTrig:
                kwSearch(k, mTrig)
                # time.sleep(6)
            else:
                kwSearch(k)
                # time.sleep(6)
    else:
       for k in testArray:
            kwSearch(k, mTrig)
            time.sleep(6)
    csvfile.close()


def dupeCheck():
    print("Eliminating Duplicates")
    with open("cve.csv", "r") as in_f, open("cve_unduped.csv", "w", newline="") as out_f:
        seen = set()
        for line in in_f:
            linedata = line.split(",")
            cves = linedata[0]
            if cves in seen:
                # print(cves)
                continue
            seen.add(cves)
            out_f.write(line)
        print("Trimmed Duplicates: "+str(len(seen)))
    in_f.close()
    out_f.close()


def checkSearchDupes(searchTerms):
    print("Checking for Search Term Duplicates...")
    setTerms = set()
    for term in searchTerms:
        if term in setTerms:
            sys.exit("Found Duplicate Term: " + term)
        else:
            setTerms.add(term)
    print("No duplicate Search Terms found, moving on...")


def sendToTeams():
    url = os.getenv("TEAMS_HOOK")
    if str(url) == "":
        sys.exit("TEAMS_HOOK not found")
    print("Sending to Teams")
    # f = open('teams_hook.txt','r')
    # url = f.read()
    # f.close()
    headers = {"Content-Type": "application/json"}
    payload = {
        "text": "New Report posted in Repo https://raw.githubusercontent.com/SecurityTapestry-Queen/nvd-cve-api-search/main/cves.xlsx"
        +"<br>"
        + "New HTML https://securitytapestry-queen.github.io/nvd-cve-api-search/cve_tables.html"
    }
    r = requests.post(url, headers=headers, data=json.dumps(payload))
    # print(r.text.encode("utf8"))
    # sys.exit('Done!')

def wrapLinks():
    df = pd.read_csv('cve_unduped.csv', encoding=encodingLin)
    for index,row in df.iloc[0:].iterrows():
        link = row[5]
        anchor = f'<a href="{link}">Info Link</a>'
        df.at[index, 'Link'] = anchor
    df.to_csv('cve_forhtml.csv', index=False)

def makeHtml():
    print('Making HTML')
    wrapLinks()
    in_f = pd.read_csv('cve_forhtml.csv', encoding=encodingLin)
    tables = in_f.to_html(index=False, table_id="cve-table", classes="sortable")
    docsDir = "docs/"
    file = open(docsDir+"cve_tables.html","w")
    file.write(
          "<!DOCTYPE html><html>"+"\n"
        + "<head>"+"\n"
        + "<title>CVE Report</title>"+"\n"
        + "<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">"+"\n"
        + "<link rel=\"icon\" type=\"image/x-icon\" href=\"favicon.ico\">"+"\n"
        + "<link rel=\"stylesheet\" href=\"assets/dataframe.css\">"+"\n"
        + "<link rel=\"stylesheet\" href=\"assets/filtertable.css\">"+"\n"
        + "<script src=\"assets/sorttable.js\">"+"</script>"+"\n"
        + "</head><body>" + "\n"
        # + "<div><p>"
        # + "Keywords Used:"+"\n"
        # + str(kwArray)
        # + "</p></div>"
        + "<div class=\"table-container\">"+"\n"
        + "<input type=\"text\" id=\"myInput\" onkeyup=\"filterTable()\" placeholder=\"Search keywords..\">"+"\n"
        + tables +"\n"
        + "<script src=\"assets/filtertable.js\">"+"</script>"+"\n"
        + "</div>"+"\n"
        + "</body>"+"\n"
        + "</html>"
        )
    print('Saved to docs/cve_tables.html')

def csvExcel(csv, excel):
    print("Making Excel")
    df = pd.read_csv(csv, encoding=encodingLin)
    writer = pd.ExcelWriter(excel)
    df.to_excel(writer, index=False)
    writer.close()

def dayArchiveCheck():
    global dayArchive
    dayArchive = archivePath+date_today
    isExist = os.path.exists(dayArchive)
    if not isExist:
        os.makedirs(dayArchive)
        print("Day Archive Created: "+dayArchive)
    else:
        print("Day Archive Exists: "+dayArchive)

def archiveMachine(csv,excel,html):
    os.system("cp "+csv+" "+dayArchive+"/report-"+date_time+".csv")
    print("CSV Archived to "+dayArchive+"/report-"+date_time+".csv")
    os.system("cp "+excel+" "+dayArchive+"/report-"+date_time+".xlsx")
    print("XLSX Archived to "+dayArchive+"/report-"+date_time+".xlsx")
    os.system("cp "+html+" "+dayArchive+"/report-"+date_time+".html")
    print("HTML Archived to "+dayArchive+"/report-"+date_time+".html")

kwArray = [
".NET Framework",
"ADX","AWS","Adobe","Airflow","Airwatch","Amazon","Apache","Apple","Arris","Aruba","Atlassian","Azure","Atom","ASP.NET","Artificial Intelligence","AnyDesk","AnyConnect","Atomic Red Team","Active Directory","Ansible","AMD64",
"BusyBox","Biometric","Bitcoin","Barracuda","Botnet","BitLocker",
"CSRF","Carbon Black","Cisco","Citrix","Crowdstrike","Cryptocurrency","Cryptograph","ChatGPT","CRM","CyberChef","Chef",
"D-Link","Darktrace","Defender","Dell","Discourse","Django","Docker","Dolibarr","Debian","DDoS","DRAGOS","Dynamics 365",
"EMC","ESXi","Eclipse","Elasticsearch","Ethereum","Excel","Exchange","Encyption","Exploit","ExtraHop","ExpressVPN","Endpoint",
"Fortinet","Freshworks","FreshService","Firewall","Fortra",
"GIS","GitLab","Golang","Google","Gradle","Grafana","GPT","GoAnywhere","GitHub",
"HPE","Hewlett-Packard","Hadoop","HashiCorp","Hyper-V",
"IBM","IOBit","Intel","IoT","InTune","Insight",
"Java","Jenkins","JetBrains","Juniper","JQuery","Jira","JavaScript","JDK","JRE",
"Kibana","Kubernetes","KeePass","Kaspersky",
"Lenovo","Linux","Llama","Litecoin","LogMeIn","LastPass",
"MSI","Management","Mattermost","Microsoft","MongoDB","MySQL","MacOS","MariaDB","Malware","MFA","Multi-factor Authentication","Midjourney","Machine Learning","MDR","MFT","MDM","McAfee","Malwarebytes","Mozilla",
"NVIDIA","Netgear","Nextcloud","Nginx","Node.js","NoSQL","Nexpose","Nessus","NPM","NULL Pointer",
"OAuth","Office365","Okta","OpenSSL","Oracle","Outlook","Office","OpenAI","OneDrive","OneNote","Office 365","OpenSSH","Orchestration","Orchestrator",
"PHP","Palo Alto","Powerpoint","Proofpoint","Python","Phishing","PipeDrive","Puppet",
"QEMU","QGIS","Quantum",
"RDP","Rapid7","Red Canary","Red Hat","Redis","Ransomware","Rootkit","Remote Desktop","Radeon","Repository","Repo",
"SAP","SNMP","SQL","SSL","STARTTLS","SUSE","SentinelOne","SharePoint","Slack","Snapdragon","Solarwinds","StarWind","Samba","Spyware","Stable Diffusion","Symantec","SIP","SSH",
"TLS","Tenda","TensorFlow","TeamViewer",
"Ubiquity","Ubuntu",
"VMware","VNC","VPN","Visual Studio","VirtualBox","VS Code","VoIP","Vim","Virtual Machine",
"Win32k","Windows","WordPress","Wyse","Win64","WMI","WireGuard","Webex",
"Xen","Xterm","XSS","X86","X64","X86_64",
"Zoho","Zoom","Zyxel","ZoneEdit","ZoneMinder",
]

testArray = ["PHP","Bitcoin","Dell"]

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="NVD CVE API Scraping Bot")
    parser.add_argument(
        "-m",
        "--mini-csv",
        help="Only checks for a few CVEs per Search Term",
        action="store_true",
        dest="Mini",
        default=False,
    )
    parser.add_argument(
        "-M",
        "--maxi-csv",
        help="Full-Sized Search",
        action="store_true",
        dest="Maxi",
        default=False,
    )
    parser.add_argument(
        "-test",
        "--testing",
        help="Test Search",
        action="store_true",
        dest="Test",
        default=False,
    )
    parser.add_argument(
        "-teams",
        "--send-to-teams",
        help="Sends Link to Teams Channel",
        action="store_true",
        dest="SendToTeams",
        default=False,
    )
    parser.add_argument(
        "-html",
        "--html-tables",
        help="Converts Output CSV to HTML Tables",
        action="store_true",
        dest="MakeHtml",
        default=False,
    )
    parser.add_argument(
        "-e",
        "--excel",
        help="Converts final CSV to Excel file",
        action="store_true",
        dest="MakeExcel",
        default=False,
    )
    parser.add_argument(
        "-a",
        "--archiver",
        help="Archives CSV, HTML, and XLSX",
        action="store_true",
        dest="Archiver",
        default=False
    )
    args = parser.parse_args()

    if sys.version_info < (3, 10):
        sys.exit("Please use Python 3.10+")
    print("Search Terms Used:")

    if args.Mini:
        print(*kwArray, sep=", ")
        checkSearchDupes(kwArray)
        print("Mini Mode On")
        csvWriter(True)
        dupeCheck()

    if args.Maxi:
        print(*kwArray, sep=", ")
        checkSearchDupes(kwArray)
        print("Maxi Mode On")
        csvWriter()
        dupeCheck()

    if args.Test:
        print(*testArray, sep=", ")
        checkSearchDupes(testArray)
        print("Test Mode On")
        csvWriter(True,True)
        dupeCheck()

    if args.MakeHtml:
        makeHtml()

    if args.MakeExcel:
        csvExcel('cve_unduped.csv','cves.xlsx')

    if args.Archiver:
        dayArchiveCheck()
        archiveMachine("cve_unduped.csv","cves.xlsx","docs/cve_tables.html")

    if args.SendToTeams:
        sendToTeams()

    print('Done!')