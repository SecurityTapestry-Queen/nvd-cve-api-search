"""NVD CVE API Keyword Search"""
import json
import time
import csv
import sys
import os
from datetime import datetime, timedelta
import argparse
import pandas as pd
import openpyxl
import requests
import pytz

# Global Variables Declaration
global csv_write # pylint: disable=W0604
global day_archive # pylint: disable=W0604
global keyword # pylint: disable=W0604
# GVD End

# Constant Variable Declaration
OPX = openpyxl
ARCHIVE_PATH = "archive/"
CST = pytz.timezone("America/Chicago")
NOW = datetime.now(CST)
DATE_TIME = NOW.strftime("%m-%d-%Y-%H-%M-%S")
DATE_TODAY = NOW.strftime("%Y-%m-%d")
# CVD End

# Encoding Declaration
ENCODING_WINDOWS="cp1252"
ENCODING_LINUX="utf-8"
# Encoding End

def get_api_key():
    """Retrieves API_KEY for NVD"""
    # api_txt = open('api_key.txt','r')
    # API_KEY = api_txt.read()
    # api_txt.close()
    api_key = os.getenv("NVD_API_KEY")
    if str(api_key) == "":
        print("Warning: NVD API Key not found, you may experience rate-limiting. Use -test or add API_KEY")
    return api_key


def keyword_search(keywords, mini_trig=False):
    """Searching NVD API with keywords"""
    print("Searching for New/Modified CVEs for " + str(keywords))
    now_time = datetime.now().strftime("%Y-%m-%dT%H:%M:%S.%fZ")
    delta = datetime.now() - timedelta(days=7)  # Only Modified since last week
    lastweek = delta.strftime("%Y-%m-%dT%H:%M:%S.%fZ")
    url = "https://services.nvd.nist.gov/rest/json/cves/2.0/"
    headers = {"apiKey": get_api_key()}
    params = {
        "keywordSearch": keywords,
        "lastModStartDate": lastweek,
        "lastModEndDate": now_time,
    }
    if mini_trig:
        params.update({"resultsPerPage": "5"})  # If mTrig is True, trigger Mini Mode
    request = requests.get(url, headers=headers, params=params, timeout=30)
    try:
        cves = request.json()
        for cve in cves["vulnerabilities"]:
            cve_id = cve["cve"]
            descriptions = str(cve_id["descriptions"][0]["value"])
            print(str(cve_id["id"]))
            # print(
            # "CVE: " + str(c['id']) + "\n"
            # "Last Modified: " + str(c['lastModified']) + "\n"
            # "Description: " + str(c['descriptions'][0]['value'])
            # )
            if "cvssMetricV31" in cve_id["metrics"]:
                # print("Impact Score V31: " + str(c['metrics']['cvssMetricV31'][0]['impactScore']) + "\n")
                csv_write.writerow(
                    [
                        str(cve_id["id"]),
                        str(cve_id["metrics"]["cvssMetricV31"][0]["impactScore"]),
                        str(keyword), # pylint: disable=E0601
                        # str(c["descriptions"][0]["value"]),
                        ''.join(descriptions.splitlines()),
                        str(cve_id["lastModified"]),
                        str("https://cve.circl.lu/cve/"+cve_id["id"]),
                    ]
                )
            elif "cvssMetricV30" in cve_id["metrics"]:
                # print("Impact Score V2: " + str(c['metrics']['cvssMetricV30'][0]['impactScore']) + "\n")
                csv_write.writerow(
                    [
                        str(cve_id["id"]),
                        str(cve_id["metrics"]["cvssMetricV30"][0]["impactScore"]),
                        str(keyword),
                        # str(c["descriptions"][0]["value"]),
                        ''.join(descriptions.splitlines()),
                        str(cve_id["lastModified"]),
                        str("https://cve.circl.lu/cve/"+cve_id["id"]),
                    ]
                )
            elif "cvssMetricV2" in cve_id["metrics"]:
                # print("Impact Score V2: " + str(c['metrics']['cvssMetricV2'][0]['impactScore']) + "\n")
                csv_write.writerow(
                    [
                        str(cve_id["id"]),
                        str(cve_id["metrics"]["cvssMetricV2"][0]["impactScore"]),
                        str(keyword),
                        # str(c["descriptions"][0]["value"]),
                        ''.join(descriptions.splitlines()),
                        str(cve_id["lastModified"]),
                        str("https://cve.circl.lu/cve/"+cve_id["id"]),
                    ]
                )
            else:
                # continue
                csv_write.writerow(
                    [
                        str(cve_id["id"]),
                        str("NA"),
                        str(keyword),
                        # str(c["descriptions"][0]["value"]),
                        ''.join(descriptions.splitlines()),
                        str(cve_id["lastModified"]),
                        str("https://cve.circl.lu/cve/"+cve_id["id"]),
                    ]
                )
            # print(c)
        # print(cves)
    except requests.RequestException as request_exeption:
        print("Error: ", request_exeption, " ", keywords, " ", request.status_code)  # exception for bad API requests


def csv_writer(mini_trig=False,test_trigger=False):
    """CSV creator"""
    print("Writing CSV")
    csv_file = open("cve.csv", mode="w", newline="", encoding=ENCODING_LINUX)
    global csv_write # pylint: disable=W0601
    csv_write = csv.writer(
        csv_file,
        dialect="excel",
        delimiter=",",
        quotechar='"',
        quoting=csv.QUOTE_MINIMAL,
    )
    csv_write.writerow(["CVE", "Impact Score (1-10, 10 being the worst)", "Keyword", "Description", "Last Modified", "Link"])
    # csvwrite.writerow(['1234','1.2','test description','11-1-11'])
    global keyword # pylint: disable=W0601
    if not test_trigger:
        for keyword in KEYWORD_ARRAY:
            if mini_trig:
                keyword_search(keyword, mini_trig)
                time.sleep(2)
            else:
                keyword_search(keyword)
                time.sleep(2)
    else:
        for keyword in TEST_ARRAY:
            keyword_search(keyword, mini_trig)
            time.sleep(2)
    csv_file.close()


def dupe_check():
    """Checks for Duplicates and eliminates them"""
    print("Eliminating Duplicates")
    with open("cve.csv", "r", encoding=ENCODING_LINUX) as in_f, open("cve_unduped.csv", "w", newline="", encoding=ENCODING_LINUX) as out_f:
        seen = set()
        for line in in_f:
            linedata = line.split(",")
            cves = linedata[0]
            if cves in seen:
                # print(cves)
                continue
            seen.add(cves)
            out_f.write(line)
        print("Trimmed Duplicates: "+str(len(seen)))
    in_f.close()
    out_f.close()


def check_search_dupes(search_terms):
    """Checks for duplicates in the keyword array"""
    print("Checking for Search Term Duplicates...")
    set_terms = set()
    for term in search_terms:
        if term in set_terms:
            sys.exit("Found Duplicate Term: " + term)
        else:
            set_terms.add(term)
    print("No duplicate Search Terms found, moving on...")


def send_to_teams():
    """Sends alert to specified MS Teams channel"""
    url = os.getenv("TEAMS_HOOK")
    if str(url) == "":
        sys.exit("TEAMS_HOOK not found")
    print("Sending to Teams")
    # f = open('teams_hook.txt','r')
    # url = f.read()
    # f.close()
    headers = {"Content-Type": "application/json"}
    payload = {
        "text": "New Report posted in Repo https://raw.githubusercontent.com/SecurityTapestry-Queen/nvd-cve-api-search/main/cve_unduped.csv"
        +"<br>"
        + "New HTML https://securitytapestry-queen.github.io/nvd-cve-api-search/index.html"
    }
    requests.post(url, headers=headers, data=json.dumps(payload), timeout=30)
    # print(r.text.encode("utf8"))
    # sys.exit('Done!')

def make_html():
    """Makes the HTML"""
    print('Making HTML')
    in_f = pd.read_csv('cve_unduped.csv')
    # in_f = pd.read_csv('cve_unduped.csv', encoding=encodingLin)
    tables = in_f.to_html(index=False, table_id="cve-table", classes="sortable", render_links=True, na_rep="N/A")
    # tables = "<a>testing anchor</a>"
    docs_directory = "docs/"
    file = open(docs_directory+"index.html","w", encoding=ENCODING_LINUX)
    file.write(
          "<!DOCTYPE html><html>"+"\n"
        + "<head>"+"\n"
        + "<title>CVE Report</title>"+"\n"
        + "<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">"+"\n"
        + "<link rel=\"icon\" type=\"image/x-icon\" href=\"favicon.ico\">"+"\n"
        + "<link rel=\"stylesheet\" href=\"assets/dataframe.css\">"+"\n"
        + "<link rel=\"stylesheet\" href=\"assets/filtertable.css\">"+"\n"
        + "<script src=\"assets/sorttable.js\">"+"</script>"+"\n"
        + "</head><body>" + "\n"
        # + "<div><p>"
        # + "Keywords Used:"+"\n"
        # + str(kwArray)
        # + "</p></div>"
        + "<div class=\"table-container\">"+"\n"
        + "<input type=\"text\" id=\"myInput\" onkeyup=\"filterTable()\" placeholder=\"Search keywords..\">"+"\n"
        + tables +"\n"
        + "<script src=\"assets/filtertable.js\">"+"</script>"+"\n"
        + "</div>"+"\n"
        + "</body>"+"\n"
        + "</html>"
        )
    print('Saved to docs/index.html')

def day_archive_check():
    """Checks for the Archive's existence, and creates if not there"""
    global day_archive # pylint: disable=W0601
    day_archive = ARCHIVE_PATH+DATE_TODAY
    it_exists = os.path.exists(day_archive)
    if not it_exists:
        os.makedirs(day_archive)
        print("Day Archive Created: "+day_archive)
    else:
        print("Day Archive Exists: "+DATE_TODAY)

def archive_machine(file):
    """Creates Archives"""
    os.system("cp "+file+" "+day_archive+"/report-"+DATE_TIME+".csv")
    print("CSV Archived to "+day_archive+"/report-"+DATE_TIME+".csv")

KEYWORD_ARRAY = [
".NET Framework",
"ADX","AWS","Adobe","Airflow","Airwatch","Amazon","Apache","Apple","Arris","Aruba","Atlassian","Azure","Atom","ASP.NET","Artificial Intelligence","AnyDesk","AnyConnect","Atomic Red Team","Active Directory","Ansible","AMD64","Akamai","AMP",
"BlackBerry","BusyBox","Biometric","Bitcoin","Barracuda","Botnet","BitLocker","Broadcom","BitDefender",
"CSRF","Carbon Black","Cisco","Citrix","Crowdstrike","Cryptocurrency","Cryptograph","ChatGPT","CRM","CyberChef","Chef","Cylance","Cybereason","Cynet",
"D-Link","Darktrace","Defender","Dell","Discourse","Django","Docker","Dolibarr","Debian","DDoS","DRAGOS","Dynamics 365","Deep Instinct",
"EMC","ESXi","Eclipse","Elasticsearch","Ethereum","Excel","Exchange","Encyption","Exploit","ExtraHop","ExpressVPN","Endpoint",
"Fortinet","Freshworks","FreshService","Firewall","Fortra",
"GIS","GitLab","Golang","Google","Gradle","Grafana","GPT","GoAnywhere","GitHub",
"HPE","Hewlett-Packard","Hadoop","HashiCorp","Hyper-V",
"IBM","IOBit","Intel","IoT","InTune","Insight",
"Java","Jenkins","JetBrains","Juniper","JQuery","Jira","JavaScript","JDK","JRE",
"Kibana","Kubernetes","KeePass","Kaspersky",
"Lenovo","Linux","Llama","Litecoin","LogMeIn","LastPass",
"MSI","Management","Mattermost","Microsoft","MongoDB","MySQL","MacOS","MariaDB","Malware","MFA","Multi-factor Authentication","Midjourney","Machine Learning","MDR","MFT","MDM","McAfee","Malwarebytes","Mozilla","Mimecast",
"NVIDIA","Netgear","Nextcloud","Nginx","Node.js","NoSQL","Nexpose","Nessus","NPM","NULL Pointer",
"OAuth","Office365","Okta","OpenSSL","Oracle","Outlook","Office","OpenAI","OneDrive","OneNote","Office 365","OpenSSH","Orchestration","Orchestrator",
"PHP","Palo Alto","Powerpoint","Proofpoint","Python","Phishing","PipeDrive","Puppet","Prisma",
"QEMU","QGIS","Quantum",
"RDP","Rapid7","Red Canary","Red Hat","Redis","Ransomware","Rootkit","Remote Desktop","Radeon","Repository","Repo",
"SAP","SNMP","SQL","SSL","STARTTLS","SUSE","SentinelOne","SharePoint","Slack","Snapdragon","Solarwinds","StarWind","Samba","Spyware","Stable Diffusion","Symantec","SIP","SSH","SES",
"TLS","Tenda","TensorFlow","TeamViewer","TAP",
"Ubiquity","Ubuntu",
"VMware","VNC","VPN","Visual Studio","VirtualBox","VS Code","VoIP","Vim","Virtual Machine",
"Win32k","Windows","WordPress","Wyse","Win64","WMI","WireGuard","Webex",
"Xen","Xterm","XSS","X86","X64","X86_64",
"Zoho","Zoom","Zyxel","ZoneEdit","ZoneMinder",
]

TEST_ARRAY = ["PHP","Bitcoin","Dell"]

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="NVD CVE API Scraping Bot")
    parser.add_argument(
        "-m",
        "--mini-csv",
        help="Only checks for a few CVEs per Search Term",
        action="store_true",
        dest="Mini",
        default=False,
    )
    parser.add_argument(
        "-M",
        "--maxi-csv",
        help="Full-Sized Search",
        action="store_true",
        dest="Maxi",
        default=False,
    )
    parser.add_argument(
        "-test",
        "--testing",
        help="Test Search",
        action="store_true",
        dest="Test",
        default=False,
    )
    parser.add_argument(
        "-teams",
        "--send-to-teams",
        help="Sends Link to Teams Channel",
        action="store_true",
        dest="SendToTeams",
        default=False,
    )
    parser.add_argument(
        "-html",
        "--html-tables",
        help="Converts Output CSV to HTML Tables",
        action="store_true",
        dest="MakeHtml",
        default=False,
    )
    parser.add_argument(
        "-a",
        "--archiver",
        help="Archives CSV",
        action="store_true",
        dest="Archiver",
        default=False
    )
    args = parser.parse_args()

    if sys.version_info < (3, 10):
        sys.exit("Please use Python 3.10+")
    print("Search Terms Used:")

    if args.Mini:
        print(*KEYWORD_ARRAY, sep=", ")
        check_search_dupes(KEYWORD_ARRAY)
        print("Mini Mode On")
        csv_writer(True)
        dupe_check()

    if args.Maxi:
        print(*KEYWORD_ARRAY, sep=", ")
        check_search_dupes(KEYWORD_ARRAY)
        print("Maxi Mode On")
        csv_writer()
        dupe_check()

    if args.Test:
        print(*TEST_ARRAY, sep=", ")
        check_search_dupes(TEST_ARRAY)
        print("Test Mode On")
        csv_writer(True,True)
        dupe_check()

    if args.MakeHtml:
        make_html()

    if args.Archiver:
        day_archive_check()
        archive_machine("cve_unduped.csv")

    if args.SendToTeams:
        send_to_teams()

    print('Done!')
